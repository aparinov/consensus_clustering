{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26088f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_consenus_matrix(N, partitions):\n",
    "    consensus_matrix = np.zeros((N, N))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            count = sum(partitions[k][i] == partitions[k][j] for k in range(len(partitions)))\n",
    "            consensus_matrix[i, j] = count\n",
    "    return consensus_matrix\n",
    "\n",
    "def modularity_shift(N, matrix):\n",
    "    shifted_matrix = matrix\n",
    "    row_sums = shifted_matrix.sum(0)\n",
    "    overall_sum = shifted_matrix.sum()\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            shifted_matrix[i,j] -= row_sums[i] * row_sums[j] / overall_sum\n",
    "    return shifted_matrix\n",
    "\n",
    "def scale_shift(N,matrix):\n",
    "    shifted_matrix = matrix\n",
    "    average = shifted_matrix.sum()/N*N\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            shifted_matrix[i,j] -= average\n",
    "    return shifted_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agsu(N, all_partitions, criterion='av'):\n",
    "\n",
    "    # Get consensus matrix\n",
    "    consensus_matrix = create_consenus_matrix(N,all_partitions)\n",
    "\n",
    "    # Modularity-shift\n",
    "    shifted_matrix = modularity_shift(N,consensus_matrix)\n",
    "\n",
    "    # Partitioning initialisation\n",
    "    clusters = [[i] for i in range(len(consensus_matrix))]\n",
    "    max_delta = 1\n",
    "    while len(clusters) > 2 and max_delta > 0:\n",
    "        max_delta = 0\n",
    "        best_s, best_t = 0, 0\n",
    "        for s in range(len(consensus_matrix)):\n",
    "            for t in range(s + 1, len(consensus_matrix)):\n",
    "                cur_delta = consensus_matrix[s,t]\n",
    "                if criterion == 'av':\n",
    "                    cur_delta /= (len(clusters[s]) + len(clusters[t]))\n",
    "                if cur_delta > max_delta:\n",
    "                    max_delta = cur_delta\n",
    "                    best_s, best_t = s, t\n",
    "\n",
    "        if max_delta > 0:\n",
    "            clusters[best_s] += clusters[best_t]\n",
    "            del clusters[best_t]\n",
    "\n",
    "            consensus_matrix[best_s, :] += consensus_matrix[best_t, :]\n",
    "            consensus_matrix[:, best_s] += consensus_matrix[:, best_t]\n",
    "            consensus_matrix = np.delete(consensus_matrix, best_t, axis=0)  \n",
    "            consensus_matrix = np.delete(consensus_matrix, best_t, axis=1)  \n",
    "\n",
    "    cluster_labels = np.empty(N, dtype=int)\n",
    "\n",
    "    for cluster_idx, cluster in enumerate(clusters):\n",
    "        cluster_labels[cluster] = cluster_idx\n",
    "    \n",
    "    return cluster_labels\n",
    "\n",
    "def agsa(N, all_partitions, criterion='av'):\n",
    "\n",
    "    # Get consensus matrix\n",
    "    consensus_matrix = create_consenus_matrix(N,all_partitions)\n",
    "    # Modularity-shift\n",
    "    shifted_matrix = modularity_shift(N,consensus_matrix)\n",
    "\n",
    "    clusters = [[i] for i in range(len(consensus_matrix))]\n",
    "    max_delta = 1\n",
    "    while len(clusters) > 2 and max_delta > 0:\n",
    "        max_delta = 0\n",
    "        best_s, best_t = 0, 0\n",
    "        for s in range(len(consensus_matrix)):\n",
    "            for t in range(s + 1, len(consensus_matrix)):\n",
    "                cur_delta = consensus_matrix[s,t]\n",
    "                if criterion == 'av':\n",
    "                    cur_delta /= (len(clusters[s]) + len(clusters[t]))\n",
    "                if cur_delta > max_delta:\n",
    "                    max_delta = cur_delta\n",
    "                    best_s, best_t = s, t\n",
    "\n",
    "        if max_delta > 0:\n",
    "            clusters[best_s] += clusters[best_t]\n",
    "            del clusters[best_t]\n",
    "\n",
    "            consensus_matrix[best_s, :] += consensus_matrix[best_t, :]\n",
    "            consensus_matrix[:, best_s] += consensus_matrix[:, best_t]\n",
    "            consensus_matrix = np.delete(consensus_matrix, best_t, axis=0)  \n",
    "            consensus_matrix = np.delete(consensus_matrix, best_t, axis=1)  \n",
    "\n",
    "    cluster_labels = np.empty(N, dtype=int)\n",
    "\n",
    "    for cluster_idx, cluster in enumerate(clusters):\n",
    "        cluster_labels[cluster] = cluster_idx\n",
    "    \n",
    "    return cluster_labels\n",
    "\n",
    "def get_test_data(N,K, m):\n",
    "    test_dataset = np.random.rand(N,K,m) \n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bd55c1",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "_, X, _, y = train_test_split(df.drop(columns=['id', 'target']), df.target, test_size=0.01,\n",
    "                              stratify=df.target, random_state=0)\n",
    "y = y.reset_index(drop=True).apply(lambda label: int(label[-1]) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30122d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Results\n",
    "results = []\n",
    "\n",
    "N = len(X)\n",
    "for n_clusters in [4, 8]:\n",
    "    for km in [KMeans(n_clusters=n_clusters, random_state=0),\n",
    "                   MiniBatchKMeans(n_clusters=n_clusters, random_state=0)]:\n",
    "        \n",
    "        for n_features in [60, 80]:\n",
    "            for M in [10, 40]:\n",
    "            \n",
    "                np.random.seed(0)\n",
    "                ground_truth_labels = km.fit_predict(X)\n",
    "                all_partitions = []\n",
    "                \n",
    "                for i in range(M):\n",
    "                    feature_indices = np.random.choice(X.shape[1], size=n_features, replace=False)\n",
    "                    all_partitions.append(km.fit_predict(X.iloc[:, feature_indices]))\n",
    "                \n",
    "                for criterion in ['sum', 'av']:\n",
    "                    pred_labels = agsu(N, all_partitions, criterion)\n",
    "                    \n",
    "                    cons_ari = adjusted_rand_score(ground_truth_labels, pred_labels)\n",
    "                    mean_ari = np.mean([adjusted_rand_score(ground_truth_labels, all_partitions[i]) for i in range(M)])\n",
    "                    delta = cons_ari - mean_ari\n",
    "\n",
    "                    results.append([n_clusters, km, n_features, M, criterion, cons_ari, mean_ari, delta, len(np.unique(pred_labels))])\n",
    "\n",
    "\n",
    "columns = ['Number of clusters in initial partitioning', 'Algorithm', 'Number of features', 'Number of partitionings', 'Criteria', 'ARI ', 'Average ARI of ensamble income partitiong', 'Difference', 'Number of clusters in consensus partitioning']\n",
    "result_df = pd.DataFrame(results, columns=columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
